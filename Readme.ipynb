{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94d1b28f-80d2-43a2-8768-cbcdc8252740",
   "metadata": {},
   "source": [
    "# Web Scraping sur Wikipedia : Extraction des suffixes de noms de société par pays\n",
    "\n",
    "Ce projet utilise BeautifulSoup, une bibliothèque Python pour l'analyse HTML, afin de récupérer des données à partir du site Wikipedia. L'objectif est d'extraire les suffixes utilisés dans les noms de société pour chaque pays répertorié sur la page [List of legal entity types by country](https://en.wikipedia.org/wiki/List_of_legal_entity_types_by_country).\n",
    "\n",
    "## Description\n",
    "\n",
    "Ce projet vise à automatiser le processus d'extraction des suffixes de noms de société utilisés dans différents pays. Le scraping est effectué sur la page Wikipedia mentionnée ci-dessus, qui répertorie les types d'entités légales par pays.\n",
    "\n",
    "Le script Python utilise BeautifulSoup pour analyser le HTML de la page et extraire les informations pertinentes. Il navigue à travers la structure du DOM pour trouver les sections pertinentes pour chaque pays, puis extrait les suffixes de noms de société associés à chaque pays.\n",
    "\n",
    "Les données extraites peuvent être utilisées dans diverses applications, telles que l'analyse comparative des conventions de dénomination des sociétés dans différents pays, l'étude des pratiques commerciales internationales, etc.\n",
    "\n",
    "## Installation\n",
    "\n",
    "Pour exécuter ce projet, vous devez disposer des dépendances suivantes :\n",
    "\n",
    "- Python 3.x\n",
    "- BeautifulSoup\n",
    "\n",
    "Vous pouvez installer les dépendances en utilisant la commande suivante :\n",
    "\n",
    "```\n",
    "pip install beautifulsoup4\n",
    "```\n",
    "\n",
    "## Utilisation\n",
    "\n",
    "Pour exécuter le script de scraping, suivez les étapes suivantes :\n",
    "\n",
    "1. Clonez ce référentiel sur votre machine.\n",
    "2. Naviguez vers le répertoire du projet.\n",
    "3. Exécutez le script `scrape.py` en utilisant la commande suivante :\n",
    "\n",
    "   ```\n",
    "   python scrape.py\n",
    "   ```\n",
    "\n",
    "   Assurez-vous que vous avez une connexion Internet active pour accéder au site Wikipedia.\n",
    "\n",
    "4. Le script va parcourir la page et extraire les suffixes de noms de société pour chaque pays répertorié. Les résultats seront affichés dans la console et stockés dans un fichier CSV.\n",
    "\n",
    "   Note : Vous pouvez modifier le script pour adapter le format de stockage des données selon vos besoins.\n",
    "   \n",
    "\n",
    "## Exemples\n",
    "\n",
    "Voici quelques exemples de résultats que vous pouvez obtenir en exécutant ce projet :\n",
    "\n",
    "```\n",
    "Pays : France\n",
    "Suffixes de noms de société : SARL, SAS, SA, SCI, SNC\n",
    "\n",
    "Pays : Allemagne\n",
    "Suffixes de noms de société : GmbH, AG, KG, OHG, eG\n",
    "\n",
    "...\n",
    "\n",
    "```\n",
    "\n",
    "Ces exemples montrent les pays et les suffixes de noms de société extraits à partir de la page Wikipedia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207f6bd1-6898-45fa-bdec-92e58941012e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Pipeline pour le web scraping avec Beautiful Soup\n",
    "\n",
    "1. Installer les dépendances nécessaires :  \n",
    "   - Assurez-vous d'avoir Python installé sur votre système.\n",
    "   - Installez Beautiful Soup en exécutant la commande suivante :\n",
    "     ```\n",
    "     pip install beautifulsoup4\n",
    "     ```\n",
    "\n",
    "2. Importer les bibliothèques requises :\n",
    "   ```python\n",
    "   from bs4 import BeautifulSoup\n",
    "   import requests\n",
    "   ```\n",
    "\n",
    "3. Récupérer la page web à scraper :\n",
    "   ```python\n",
    "   url = \"https://fr.wikipedia.org/wiki/Votre_Page_Wikipedia\"\n",
    "   response = requests.get(url)\n",
    "   ```\n",
    "\n",
    "4. Parser le contenu HTML avec Beautiful Soup :\n",
    "   ```python\n",
    "   soup = BeautifulSoup(response.content, 'html.parser')\n",
    "   ```\n",
    "   \n",
    "   La ligne \"soup = BeautifulSoup(response.content, 'html.parser')\" effectue le parsing du contenu HTML en utilisant Beautiful Soup.\n",
    "\n",
    "Le terme \"parser\" dans ce contexte fait référence à un processus d'analyse ou de compréhension de la structure du document HTML. En d'autres termes, le parsing consiste à analyser le code HTML et à le décomposer en une structure hiérarchique, ce qui permet d'accéder facilement aux différentes parties du document.\n",
    "\n",
    "Dans cette ligne de code spécifique :\n",
    "\n",
    "- `response.content` est le contenu HTML brut extrait de la réponse HTTP. Il peut s'agir de l'intégralité du contenu HTML de la page web demandée.\n",
    "\n",
    "- `'html.parser'` est l'analyseur HTML utilisé par Beautiful Soup pour effectuer le parsing. Ici, nous utilisons l'analyseur intégré de Python appelé `html.parser`. Cet analyseur est capable de traiter la plupart des pages HTML bien formées.\n",
    "\n",
    "En utilisant Beautiful Soup avec l'analyseur spécifié, la ligne de code crée un objet `soup` qui représente le contenu HTML analysé et structuré. Cet objet `soup` peut ensuite être utilisé pour naviguer, extraire et manipuler les données du document HTML de manière plus conviviale à l'aide de méthodes fournies par Beautiful Soup.\n",
    "\n",
    "5. Identifier les éléments cibles à extraire :\n",
    "   Utilisez les méthodes et attributs de Beautiful Soup pour trouver les balises HTML correspondant aux informations que vous souhaitez extraire.\n",
    "\n",
    "6. Extraire les données souhaitées :\n",
    "   Utilisez les méthodes et attributs de Beautiful Soup pour extraire les données des balises HTML identifiées à l'étape précédente.\n",
    "\n",
    "7. Traiter les données extraites :\n",
    "   Si nécessaire, effectuez des manipulations supplémentaires sur les données extraites pour les mettre dans un format souhaité.\n",
    "\n",
    "8. Afficher ou enregistrer les données :\n",
    "   Affichez les données extraites à l'écran ou enregistrez-les dans un fichier selon vos besoins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aba1971-d173-437e-821c-af8836c0a9a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
